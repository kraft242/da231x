{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_csv = \"scores.csv\"\n",
    "df = pd.read_csv(scores_csv)\n",
    "print(df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_values(df, column):\n",
    "    return df[column].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMAL = \"minimal\"\n",
    "FLUENCY = \"fluency\"\n",
    "VIKING = \"Viking\"\n",
    "UAM_CSI = \"UAM-CSI\"\n",
    "GLEU = \"GLEU\"\n",
    "PRECISION = \"Precision\"\n",
    "RECALL = \"Recall\"\n",
    "F05 = \"F0.5\"\n",
    "SCRIBENDI_SCORE = \"Scribendi Score\"\n",
    "versions = [MINIMAL, FLUENCY]\n",
    "teams = [VIKING, UAM_CSI]\n",
    "metrics = [GLEU, PRECISION, RECALL, F05, SCRIBENDI_SCORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"System\", \"Correction Style\", \"Essay ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_team_version_metric(team, version, metric):\n",
    "    return df[(df[\"System\"] == team) & (df[\"Correction Style\"] == version)][\n",
    "        metric\n",
    "    ].to_numpy()\n",
    "\n",
    "\n",
    "def extract_team_version(team, version):\n",
    "    return {\n",
    "        metric: extract_team_version_metric(team, version, metric) for metric in metrics\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_team(team):\n",
    "    return {version: extract_team_version(team, version) for version in versions}\n",
    "\n",
    "\n",
    "values = {team: extract_team(team) for team in teams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_metrics = [GLEU, PRECISION, RECALL, F05]\n",
    "ordinal_metrics = [SCRIBENDI_SCORE]\n",
    "alpha = 0.05\n",
    "\n",
    "metric_tests = [\n",
    "    (continuous_metrics, ttest_rel),\n",
    "    (ordinal_metrics, wilcoxon),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for metrics, test_function in metric_tests:\n",
    "    for metric in metrics:\n",
    "        for version in versions:\n",
    "            test_result = test_function(\n",
    "                values[VIKING][version][metric], values[UAM_CSI][version][metric]\n",
    "            )\n",
    "            p_value = test_result.pvalue\n",
    "            significant = p_value < alpha\n",
    "            result_dict = {\n",
    "                \"metric\": metric,\n",
    "                \"version\": version,\n",
    "                \"p_value\": p_value,\n",
    "                \"significant\": significant,\n",
    "            }\n",
    "            results.append(result_dict)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
