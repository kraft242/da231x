{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Evaluation\n",
    "\n",
    "This notebook performs the automatic evaluation of the system outputs.\n",
    "\n",
    "Make sure you have read the `README` in this directory and installed all required packages.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs, popen, system\n",
    "import re\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "from itertools import product\n",
    "from syntok.tokenizer import Tokenizer\n",
    "from scribendi import ScribendiScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2DIR = \"../m2/\"\n",
    "REPO_ROOT = \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processsing Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretokenize(txt):\n",
    "    tok = Tokenizer()\n",
    "    return \" \".join([str(token).strip() for token in tok.tokenize(txt)])\n",
    "\n",
    "\n",
    "NEWLINE = \"\\n\"\n",
    "SPACE = \" \"\n",
    "\n",
    "\n",
    "def convert_essay_to_single_line(essay: str):\n",
    "    \"\"\"\n",
    "    Replace all newlines (\"\\\\n\") in essay with spaces (\" \").\n",
    "    \"\"\"\n",
    "    return essay.replace(NEWLINE, SPACE)\n",
    "\n",
    "\n",
    "def md_to_dict(md):\n",
    "    \"\"\"\n",
    "    Parse shared task format into a dictionary where keys are essay IDs\n",
    "    and values are essay texts.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "    md --- a string with the content of a shared task Markdown file.\n",
    "    \"\"\"\n",
    "    essay_dict = {}\n",
    "    for essay in md.split(\"### essay_id = \")[1:]:\n",
    "        (essay_id, text) = essay.split(\"\\n\", maxsplit=1)\n",
    "        text_tokenized = pretokenize(text).strip(\"\\n\")\n",
    "        essay_dict[essay_id] = convert_essay_to_single_line(text_tokenized)\n",
    "    return essay_dict\n",
    "\n",
    "\n",
    "def write_essay_to_file(output_dir, essay_id, essay_text):\n",
    "    file_name = f\"{essay_id}\".tmp\n",
    "    file_path = path.join(output_dir, file_name)\n",
    "    with open(file_path, \"w+\") as f:\n",
    "        f.write(essay_text)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def _ensure_directory_exists(directory):\n",
    "    makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "def split_file_per_essay(input_file, output_dir):\n",
    "    _ensure_directory_exists(output_dir)\n",
    "\n",
    "    ids_texts = md_to_dict(input_file)\n",
    "\n",
    "    file_paths = {}\n",
    "\n",
    "    for essay_id, essay_text in ids_texts.items():\n",
    "        file_path = write_essay_to_file(essay_id, essay_text)\n",
    "        file_paths[essay_id] = file_path\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMAL = \"minimal\"\n",
    "FLUENCY = \"fluency\"\n",
    "VIKING = \"Viking\"\n",
    "UAM_CSI = \"UAM-CSI\"\n",
    "\n",
    "DATA_DIR = path.join(REPO_ROOT, \"data/swedish/SweLL_gold/\")\n",
    "SOURCE_DIR = path.join(REPO_ROOT, \"sources/\")\n",
    "REFERENCE_DIR = path.join(REPO_ROOT, \"references/\")\n",
    "HYPOTHESIS_DIR = path.join(REPO_ROOT, \"hypotheses/\")\n",
    "SYSTEM_OUTPUT_DIR = path.join(REPO_ROOT, \"outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_source_paths():\n",
    "    md = path.join(DATA_DIR, \"sv-swell_gold-orig-test.md\")\n",
    "    return split_file_per_essay(md, SOURCE_DIR)\n",
    "\n",
    "\n",
    "source_paths = get_all_source_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_paths(input_file, version):\n",
    "    output_dir = path.join(REFERENCE_DIR, version)\n",
    "    return split_file_per_essay(input_file, output_dir)\n",
    "\n",
    "\n",
    "def get_all_reference_paths():\n",
    "    minimal_reference_md = path.join(DATA_DIR, \"sv-swell_gold-ref1-test.md\")\n",
    "    fluency_reference_md = path.join(DATA_DIR, \"sv-swell_gold-ref2-test.md\")\n",
    "    return {\n",
    "        MINIMAL: get_reference_paths(minimal_reference_md, MINIMAL),\n",
    "        FLUENCY: get_reference_paths(fluency_reference_md, FLUENCY),\n",
    "    }\n",
    "\n",
    "\n",
    "reference_paths = get_all_reference_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_version_hypothesis_paths(team, version, md):\n",
    "    hypothesis_dir = path.join(HYPOTHESIS_DIR, team, version)\n",
    "\n",
    "    return split_file_per_essay(md, hypothesis_dir)\n",
    "\n",
    "\n",
    "def get_system_hypothesis_paths(team):\n",
    "    minimal_hypothesis_md = path.join(\n",
    "        SYSTEM_OUTPUT_DIR, team, \"sv-swell_gold-hypo-test.md\"\n",
    "    )\n",
    "    fluency_hypothesis_md = path.join(\n",
    "        SYSTEM_OUTPUT_DIR, team, \"sv-swell_gold-fluency-hypo-test.md\"\n",
    "    )\n",
    "    return {\n",
    "        MINIMAL: get_system_version_hypothesis_paths(\n",
    "            team, MINIMAL, minimal_hypothesis_md\n",
    "        ),\n",
    "        FLUENCY: get_system_version_hypothesis_paths(\n",
    "            team, FLUENCY, fluency_hypothesis_md\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_all_hypothesis_paths():\n",
    "    return {\n",
    "        VIKING: get_system_hypothesis_paths(VIKING),\n",
    "        UAM_CSI: get_system_hypothesis_paths(UAM_CSI),\n",
    "    }\n",
    "\n",
    "\n",
    "hypothesis_paths = get_all_hypothesis_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gleu(\n",
    "    source_file, minimal_reference_file, fluency_reference_file, hypothesis_file\n",
    "):\n",
    "    gleu_command = f\"gleu -s {source_file} -r {minimal_reference_file} {fluency_reference_file} -o {hypothesis_file} -d 4 -f -n 4 -t word\"\n",
    "\n",
    "    gleu_output = popen(gleu_command)\n",
    "    if gleu_output != \"\":\n",
    "        gleu_split = gleu_output.split()\n",
    "        gleu_score = float(gleu_split[1])\n",
    "    else:\n",
    "        gleu_score = -float(\"inf\")\n",
    "    return gleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERRANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRANT_REGEX = re.compile(r\"\\d\\.\\d+\\s+\\d\\.\\d+\\s+\\d\\.\\d+\")\n",
    "\n",
    "\n",
    "def compute_errant(\n",
    "    source_file,\n",
    "    minimal_reference_file,\n",
    "    fluency_reference_file,\n",
    "    hypothesis_file,\n",
    "    essay_id,\n",
    "    version,\n",
    "    team,\n",
    "):\n",
    "    # run ERRANT alignment for reference(s), from one-essay-per-line .tmp file(s) to M2 output (if needed)\n",
    "    reference_m2 = path.join(M2DIR, f\"{essay_id}-{version}-reference.m2\")\n",
    "    if not path.isfile(reference_m2):\n",
    "        errant_parallel_reference_command = f\"errant_parallel -orig {source_file} -cor {minimal_reference_file} {fluency_reference_file} -out {reference_m2} -lang SV\"\n",
    "        system(errant_parallel_reference_command)\n",
    "\n",
    "    # run ERRANT alignment on hypothesis file, from one-essay-per-line .md file to M2 output (if needed)\n",
    "    hypothesis_m2 = path.join(M2DIR, f\"{team}-{version}-{essay_id}.m2\")\n",
    "    if not path.isfile(hypothesis_m2):\n",
    "        errant_parallel_hypothesis_command = f\"errant_parallel -orig {source_file} -cor {hypothesis_file} -out {hypothesis_m2} -lang SV\"\n",
    "        system(errant_parallel_hypothesis_command)\n",
    "\n",
    "    # run ERRANT scoring\n",
    "    errant_compare_command = f\"errant_compare -hyp {hypothesis_m2} -ref {reference_m2}\"\n",
    "\n",
    "    errant_scores = popen(errant_compare_command).read()\n",
    "\n",
    "    # capture the output which looks like this, add prec/rec/F0.5 to the output file\n",
    "    # =========== Span-Based Correction ============\n",
    "    # TP      FP      FN      Prec    Rec     F0.5\n",
    "    # 12      4       6       0.75    0.6667  0.7317\n",
    "    # ==============================================\n",
    "\n",
    "    if errant_scores != \"\":\n",
    "        prf_search = ERRANT_REGEX.search(errant_scores)\n",
    "        prf_list = prf_search.group(0).split(\"\\t\")\n",
    "        prf_values = [x for x in prf_list if x]\n",
    "        precision = prf_values[0]\n",
    "        recall = prf_values[1]\n",
    "        f05 = prf_values[2]\n",
    "        return float(precision), float(recall), float(f05)\n",
    "    else:\n",
    "        return tuple(-float(\"inf\")) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scribendi Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribendi_scorer = ScribendiScore()\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def compute_scribendi_score(source_file, hypothesis_file):\n",
    "    source_text = read_file(source_file)\n",
    "    hypothesis_text = read_file(hypothesis_file)\n",
    "    return scribendi_scorer.score([source_text], [hypothesis_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(\n",
    "    essay_id,\n",
    "    version,\n",
    "    team,\n",
    "    source_file,\n",
    "    minimal_reference_file,\n",
    "    fluency_reference_file,\n",
    "    hypothesis_file,\n",
    "):\n",
    "    gleu = compute_gleu(\n",
    "        source_file, minimal_reference_file, fluency_reference_file, hypothesis_file\n",
    "    )\n",
    "    precision, recall, f05 = compute_errant(\n",
    "        source_file,\n",
    "        minimal_reference_file,\n",
    "        fluency_reference_file,\n",
    "        hypothesis_file,\n",
    "        essay_id,\n",
    "        version,\n",
    "        team,\n",
    "    )\n",
    "    scribendi_score = compute_scribendi_score(source_file, hypothesis_file)\n",
    "    return {\n",
    "        \"Essay ID\": essay_id,\n",
    "        \"Correction Style\": version,\n",
    "        \"System\": team,\n",
    "        \"GLEU\": gleu,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F0.5\": f05,\n",
    "        \"Scribendi Score\": scribendi_score,\n",
    "    }\n",
    "\n",
    "\n",
    "essay_ids = source_paths.keys()\n",
    "versions = [MINIMAL, FLUENCY]\n",
    "teams = [VIKING, UAM_CSI]\n",
    "\n",
    "n_iterations = len(essay_ids) * len(versions) * len(teams)\n",
    "\n",
    "all_scores_list = []\n",
    "\n",
    "for essay_id, version, team in tqdm(\n",
    "    product(essay_ids, versions, teams), total=n_iterations\n",
    "):\n",
    "    source_file = source_paths[essay_id]\n",
    "    minimal_reference_file = reference_paths[MINIMAL][essay_id]\n",
    "    fluency_reference_file = reference_paths[FLUENCY][essay_id]\n",
    "    hypothesis_file = hypothesis_paths[team][version][essay_id]\n",
    "    scores_dict = compute_scores(\n",
    "        essay_id,\n",
    "        version,\n",
    "        team,\n",
    "        source_file,\n",
    "        minimal_reference_file,\n",
    "        fluency_reference_file,\n",
    "        hypothesis_file,\n",
    "    )\n",
    "    all_scores_list.append(scores_dict)\n",
    "\n",
    "df = pd.DataFrame(all_scores_list)\n",
    "csv_file_name = \"scores.csv\"\n",
    "df.to_csv(csv_file_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
